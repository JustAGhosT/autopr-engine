"""
AutoPR Action: Enhanced Platform Detector
Detects AI development platforms across the complete ecosystem
"""

import json
import os
import re
import subprocess
from typing import Dict, List, Any, Optional, Tuple, Callable, Collection
from pydantic import BaseModel, Field
from pathlib import Path


class EnhancedPlatformDetectorInputs(BaseModel):
    repository_url: str
    commit_messages: List[str] = []
    workspace_path: str = "."
    package_json_content: Optional[str] = None
    git_log_depth: int = 50


class EnhancedPlatformDetectorOutputs(BaseModel):
    primary_platform: str
    secondary_platforms: List[str] = Field(default_factory=list)
    confidence_scores: Dict[str, float] = Field(default_factory=dict)
    workflow_type: str  # "single_platform", "hybrid_workflow", "multi_platform"
    platform_specific_configs: Dict[str, Any] = Field(default_factory=dict)
    recommended_enhancements: List[str] = Field(default_factory=list)
    migration_opportunities: List[str] = Field(default_factory=list)
    hybrid_workflow_analysis: Optional[Dict[str, Any]] = None


class EnhancedPlatformDetector:
    def __init__(self) -> None:
        # Core rapid prototyping platforms (Phase 2 original)
        self.core_platforms: Dict[str, Dict[str, Any]] = {
            "replit": {
                "files": [".replit", "replit.nix", "pyproject.toml", ".replit.json"],
                "package_scripts": ["repl-run", "replit-dev", "repl-dev"],
                "commit_patterns": [
                    "replit",
                    "exported from replit",
                    "repl.it",
                    "from replit",
                ],
                "dependencies": ["@replit/database", "replit-py"],
                "folder_patterns": [".replit_modules", "replit_modules"],
                "content_patterns": ["replit.com", "repl.co"],
            },
            "lovable": {
                "files": ["lovable.config.js", ".lovable", "lovable.json"],
                "dependencies": ["@lovable/core", "lovable-ui", "@lovable/cli"],
                "commit_patterns": [
                    "lovable",
                    "generated by lovable",
                    "lovable.dev",
                ],
                "package_scripts": ["lovable:dev", "lovable:build", "lovable:deploy"],
                "content_patterns": ["lovable.dev", "generated with lovable"],
            },
            "bolt": {
                "files": ["bolt.config.json", ".bolt", "bolt.json", ".bolt.config"],
                "package_scripts": ["bolt:dev", "bolt:build", "bolt:start"],
                "commit_patterns": [
                    "bolt.new",
                    "bolt generated",
                    "created with bolt",
                ],
                "dependencies": ["@bolt/core", "bolt-cli"],
                "content_patterns": [
                    "bolt.new",
                    "built with bolt",
                ],
            },
            "same": {
                "files": ["same.config.js", ".same", "same.json"],
                "commit_patterns": [
                    "same.new",
                    "cloned from same",
                    "same template",
                ],
                "dependencies": ["@same/core", "same-cli"],
                "package_scripts": ["same:dev", "same:clone", "same:customize"],
                "content_patterns": [
                    "same.new",
                    "cloned with same",
                ],
            },
            "emergent": {
                "files": [
                    "emergent.sh",
                    ".emergent",
                    "deploy.emergent",
                    ".emergent.yml",
                ],
                "commit_patterns": [
                    "emergent.sh",
                    "automated by emergent",
                    "emergent deploy",
                ],
                "content_patterns": [
                    "emergent.sh",
                    "emergent automation",
                ],
                "folder_patterns": [
                    "emergent_scripts",
                    ".emergent_cache",
                ],
            },
        }

        # AI Code Generation Platforms (Category 1)
        self.ai_code_platforms: Dict[str, Dict[str, Any]] = {
            "cursor": {
                "files": [
                    ".cursor/",
                    ".cursorrules",
                    "cursor.config.json",
                    ".cursor-settings",
                ],
                "dependencies": [
                    "@cursor/ai",
                    "cursor-cli",
                ],
                "commit_patterns": [
                    "cursor",
                    "generated with cursor",
                    "cursor ai",
                    "cursor ide",
                ],
                "editor_patterns": [
                    "cursor-tab-",
                    ".cursor-settings",
                ],
                "content_patterns": [
                    "cursor.sh",
                    "# Generated by Cursor",
                    "cursor.com",
                ],
                "git_patterns": [
                    "Author: Cursor",
                    "Co-authored-by: Cursor",
                ],
            },
            "copilot_workspace": {
                "files": [
                    ".github/copilot/",
                    "copilot-workspace.yml",
                    ".copilot/",
                ],
                "commit_patterns": [
                    "copilot workspace",
                    "github copilot",
                    "@github-copilot",
                    "copilot generated",
                ],
                "content_patterns": [
                    "copilot-generated",
                    "github.com/features/copilot",
                    "GitHub Copilot",
                ],
                "dependencies": [
                    "@github/copilot",
                ],
                "git_patterns": [
                    "Co-authored-by: GitHub Copilot",
                ],
            },
            "continue": {
                "files": [
                    ".continue/",
                    "continue.json",
                    ".continue.json",
                    "continue_config.py",
                ],
                "dependencies": [
                    "continue-dev",
                    "@continue/core",
                ],
                "commit_patterns": [
                    "continue.dev",
                    "continue ai",
                    "generated by continue",
                ],
                "config_patterns": [
                    "continue_config.py",
                    "config.py",
                ],
                "content_patterns": [
                    "continue.dev",
                    "# Generated by Continue",
                ],
            },
            "windsurf": {
                "files": [
                    ".windsurf/",
                    "windsurf.config.js",
                    ".codeium/",
                    "windsurf.json",
                ],
                "dependencies": [
                    "codeium",
                    "@codeium/windsurf",
                ],
                "commit_patterns": [
                    "windsurf",
                    "codeium",
                    "ai-generated",
                    "windsurf ide",
                ],
                "content_patterns": [
                    "codeium.com",
                    "windsurf ide",
                    "windsurf.dev",
                ],
            },
            "aider": {
                "files": [
                    ".aider/",
                    ".aider.conf.yml",
                    "aider.log",
                ],
                "commit_patterns": [
                    "aider:",
                    "aider ",
                    "pair programming with aider",
                ],
                "git_patterns": [
                    "Author: aider",
                    "Co-authored-by: aider",
                ],
                "content_patterns": [
                    "aider-chat",
                    "aider.chat",
                    "# aider",
                ],
            },
        }

        # Web-First AI Platforms (Category 3)
        self.web_ai_platforms: Dict[str, Dict[str, Any]] = {
            "v0_dev": {
                "files": [
                    "v0.config.js",
                    ".v0/",
                    "v0-components/",
                    "v0.json",
                ],
                "dependencies": [
                    "@v0/ui",
                    "v0-cli",
                    "@radix-ui/react-*",
                ],
                "commit_patterns": [
                    "v0.dev",
                    "generated by v0",
                    "vercel v0",
                    "v0 component",
                ],
                "content_patterns": [
                    "v0.dev",
                    "shadcn/ui",
                    "vercel ai",
                    "generated with v0",
                ],
                "folder_patterns": [
                    "components/ui/",
                    "lib/utils",
                ],
            },
            "claude_artifacts": {
                "commit_patterns": [
                    "claude artifact",
                    "anthropic claude",
                    "generated by claude",
                    "claude.ai",
                ],
                "content_patterns": [
                    "claude.ai",
                    "anthropic artifact",
                    "// Claude generated",
                    "Created with Claude",
                ],
                "files": [
                    ".claude/",
                    "claude-artifact.json",
                    "claude.config.js",
                ],
            },
            "openai_canvas": {
                "commit_patterns": [
                    "openai canvas",
                    "chatgpt canvas",
                    "generated in canvas",
                    "openai",
                ],
                "content_patterns": [
                    "openai.com",
                    "chatgpt generated",
                    "// OpenAI Canvas",
                    "Created with ChatGPT",
                ],
                "files": [
                    "canvas-project.json",
                    ".openai/",
                    "openai.config.js",
                ],
            },
        }

        # Mobile & Cross-Platform (Category 4)
        self.mobile_platforms: Dict[str, Dict[str, Any]] = {
            "flutterflow": {
                "files": [
                    "flutterflow.json",
                    ".flutterflow/",
                    "ff_project.yaml",
                    "flutterflow_config.json",
                ],
                "dependencies": [
                    "flutterflow_ui",
                    "ff_animations",
                ],
                "commit_patterns": [
                    "flutterflow",
                    "exported from flutterflow",
                    "ff export",
                ],
                "folder_patterns": [
                    "lib/flutter_flow/",
                    "assets/flutterflow/",
                ],
            },
            "draftbit": {
                "files": [
                    "draftbit.config.js",
                    ".draftbit/",
                    "draftbit.json",
                ],
                "dependencies": [
                    "@draftbit/ui",
                    "draftbit-cli",
                ],
                "commit_patterns": [
                    "draftbit",
                    "exported from draftbit",
                ],
            },
        }

        # Backend & API Platforms (Category 5)
        self.backend_platforms: Dict[str, Dict[str, Any]] = {
            "supabase_ai": {
                "files": [
                    "supabase/",
                    "supabase.config.js",
                    "supabase.json",
                ],
                "dependencies": [
                    "@supabase/supabase-js",
                    "supabase",
                ],
                "commit_patterns": [
                    "supabase ai",
                    "supabase generated",
                    "supabase magic",
                ],
                "content_patterns": [
                    "supabase.com",
                    "supabase database",
                    "supabase client",
                ],
            },
            "neon_ai": {
                "files": [
                    "neon.config.js",
                    ".neon/",
                    "neon.json",
                ],
                "dependencies": [
                    "@neon/serverless",
                    "@neondatabase/serverless",
                ],
                "commit_patterns": [
                    "neon ai",
                    "neon database",
                    "neon generated",
                ],
                "content_patterns": [
                    "neon.tech",
                    "serverless postgres",
                ],
            },
        }

        # Design-to-Code Platforms (Category 6)
        self.design_platforms: Dict[str, Dict[str, Any]] = {
            "figma_to_code": {
                "files": [
                    "figma-tokens.json",
                    ".figma/",
                    "design-tokens/",
                    "figma.config.js",
                ],
                "dependencies": [
                    "@figma/code-connect",
                    "figma-api",
                    "figma-to-react",
                ],
                "commit_patterns": [
                    "figma import",
                    "design tokens",
                    "figma to code",
                    "figma export",
                ],
                "content_patterns": [
                    "figma.com",
                    "design system",
                    "figma-generated",
                ],
                "folder_patterns": [
                    "design-tokens/",
                    "figma-assets/",
                ],
            },
            "framer": {
                "files": [
                    "framer.config.js",
                    ".framer/",
                    "framer-motion/",
                    "framer.json",
                ],
                "dependencies": [
                    "framer-motion",
                    "@framer/motion",
                    "framer",
                ],
                "commit_patterns": [
                    "framer",
                    "framer export",
                    "framer code",
                ],
                "content_patterns": [
                    "framer.com",
                    "framer motion",
                    "framer generated",
                ],
            },
        }

        # AI Code Assistants (Category 7)
        self.ai_assistants: Dict[str, Dict[str, Any]] = {
            "tabnine": {
                "files": [
                    ".tabnine/",
                    "tabnine.config.json",
                ],
                "content_patterns": [
                    "tabnine",
                    "generated by tabnine",
                    "// TabNine",
                ],
                "commit_patterns": [
                    "tabnine suggestion",
                    "ai completion",
                    "tabnine generated",
                ],
            },
            "codewhisperer": {
                "files": [
                    ".aws/codewhisperer/",
                    "codewhisperer.json",
                ],
                "commit_patterns": [
                    "codewhisperer",
                    "aws ai",
                    "amazon codewhisperer",
                ],
                "content_patterns": [
                    "aws.amazon.com/codewhisperer",
                    "// CodeWhisperer",
                ],
            },
        }

        # Infrastructure & DevOps AI (Category 8)
        self.infrastructure_platforms: Dict[str, Dict[str, Any]] = {
            "pulumi_ai": {
                "files": [
                    "Pulumi.yaml",
                    "Pulumi.*.yaml",
                    ".pulumi/",
                    "Pulumi.dev.yaml",
                    "Pulumi.prod.yaml",
                ],
                "dependencies": [
                    "@pulumi/pulumi",
                    "pulumi",
                ],
                "commit_patterns": [
                    "pulumi ai",
                    "infrastructure as code",
                    "pulumi generated",
                    "iac generated",
                ],
                "content_patterns": [
                    "pulumi.com",
                    "infrastructure ai",
                    "# Generated by Pulumi AI",
                ],
            },
            "terraform_ai": {
                "files": [
                    "main.tf",
                    "terraform.tf",
                    ".terraform/",
                    "*.tf",
                ],
                "commit_patterns": [
                    "terraform ai",
                    "ai-generated terraform",
                    "hcl generated",
                    "terraform generated",
                ],
                "content_patterns": [
                    "terraform.io",
                    "# Generated by AI",
                    "# AI-generated Terraform",
                ],
            },
        }

        # Combine all platforms
        self.all_platforms: Dict[str, Dict[str, Any]] = {
            **self.core_platforms,
            **self.ai_code_platforms,
            **self.web_ai_platforms,
            **self.mobile_platforms,
            **self.backend_platforms,
            **self.design_platforms,
            **self.ai_assistants,
            **self.infrastructure_platforms,
        }

        # Platform categories for analysis
        self.platform_categories: Dict[str, List[str]] = {
            "rapid_prototyping": list(self.core_platforms.keys()),
            "ai_code_generation": list(self.ai_code_platforms.keys()),
            "web_ai": list(self.web_ai_platforms.keys()),
            "mobile": list(self.mobile_platforms.keys()),
            "backend": list(self.backend_platforms.keys()),
            "design": list(self.design_platforms.keys()),
            "ai_assistants": list(self.ai_assistants.keys()),
            "infrastructure": list(self.infrastructure_platforms.keys()),
        }

        # Common hybrid workflow patterns
        self.hybrid_patterns: Dict[Tuple[str, str], str] = {
            ("cursor", "v0_dev"): "ai_ide_to_web_design",
            ("replit", "cursor"): "prototype_to_production_ide",
            ("figma_to_code", "lovable"): "design_system_workflow",
            ("supabase_ai", "bolt"): "backend_frontend_integration",
            ("v0_dev", "cursor"): "vercel_to_ide_workflow",
            ("claude_artifacts", "cursor"): "ai_chat_to_ide",
            ("continue", "replit"): "open_source_ai_workflow",
            ("pulumi_ai", "cursor"): "infrastructure_to_application",
        }

    def detect_platforms(
        self, inputs: EnhancedPlatformDetectorInputs
    ) -> EnhancedPlatformDetectorOutputs:
        """Enhanced platform detection with multi-platform support"""

        # Scan workspace and collect data
        file_structure: Dict[str, Any] = self._scan_workspace_enhanced(
            inputs.workspace_path
        )
        package_json: Optional[Dict[str, Any]] = self._parse_package_json(
            inputs.package_json_content, inputs.workspace_path
        )
        git_history: Dict[str, Any] = self._analyze_git_history(
            inputs.workspace_path, inputs.git_log_depth
        )

        # Detect all platforms with confidence scores
        all_scores: Dict[str, float] = {}
        detailed_analysis: Dict[str, Dict[str, Any]] = {}

        for platform, signatures in self.all_platforms.items():
            score, analysis = self._calculate_enhanced_platform_score(
                platform, signatures, inputs, file_structure, package_json, git_history
            )
            if score > 0.1:  # Include platforms with minimal evidence
                all_scores[platform] = score
                detailed_analysis[platform] = analysis

        # Determine primary and secondary platforms
        primary_platform, secondary_platforms = self._determine_platform_hierarchy(
            all_scores
        )

        # Analyze workflow type
        workflow_type, hybrid_analysis = self._analyze_workflow_type(
            all_scores, primary_platform, secondary_platforms
        )

        # Generate platform-specific configurations
        configs = self._generate_platform_configs(
            primary_platform, secondary_platforms, file_structure, package_json
        )

        # Generate recommendations and opportunities
        enhancements = self._generate_enhancement_recommendations(
            primary_platform, secondary_platforms, detailed_analysis
        )
        migrations = self._generate_migration_opportunities(
            all_scores, primary_platform
        )

        return EnhancedPlatformDetectorOutputs(
            primary_platform=primary_platform,
            secondary_platforms=secondary_platforms,
            confidence_scores=all_scores,
            workflow_type=workflow_type,
            platform_specific_configs=configs,
            recommended_enhancements=enhancements,
            migration_opportunities=migrations,
            hybrid_workflow_analysis=hybrid_analysis,
        )

    def _scan_workspace_enhanced(self, workspace_path: str) -> Dict[str, Any]:
        """Enhanced workspace scanning with deeper analysis"""
        structure: Dict[str, Any] = {
            "files": [],
            "folders": [],
            "file_contents": {},
            "file_extensions": {},
            "total_files": 0,
            "project_size": "small",  # small, medium, large
        }

        try:
            workspace = Path(workspace_path)
            if not workspace.exists():
                return structure

            # Enhanced file scanning
            for item in workspace.rglob("*"):
                if item.is_file():
                    relative_path = str(item.relative_to(workspace))
                    structure["files"].append(relative_path)
                    structure["total_files"] += 1

                    # Track file extensions
                    ext = item.suffix.lower()
                    structure["file_extensions"][ext] = (
                        structure["file_extensions"].get(ext, 0) + 1
                    )

                    # Read content of key configuration files
                    if self._is_key_file(item.name):
                        try:
                            with open(
                                item, "r", encoding="utf-8", errors="ignore"
                            ) as f:
                                content = f.read()
                                structure["file_contents"][relative_path] = content
                        except:
                            pass

                elif item.is_dir():
                    structure["folders"].append(str(item.relative_to(workspace)))

            # Determine project size
            if structure["total_files"] > 1000:
                structure["project_size"] = "large"
            elif structure["total_files"] > 100:
                structure["project_size"] = "medium"

        except Exception as e:
            print(f"Error scanning workspace: {e}")

        return structure

    def _is_key_file(self, filename: str) -> bool:
        """Determine if a file should be read for content analysis"""
        key_files: Collection[str] = {
            # Config files
            ".replit",
            "replit.nix",
            "package.json",
            "composer.json",
            "requirements.txt",
            "Dockerfile",
            "docker-compose.yml",
            ".env.example",
            ".env",
            # Platform-specific configs
            "cursor.config.json",
            ".cursorrules",
            "continue.json",
            "lovable.config.js",
            "bolt.config.json",
            "same.config.js",
            "emergent.sh",
            "v0.config.js",
            "figma-tokens.json",
            "framer.config.js",
            "supabase.config.js",
            "Pulumi.yaml",
            "main.tf",
            "terraform.tf",
            # Documentation
            "README.md",
            "readme.md",
            "README.txt",
            # CI/CD
            ".github/workflows/*.yml",
            "azure-pipelines.yml",
            ".gitlab-ci.yml",
        }

        return filename.lower() in {f.lower() for f in key_files} or any(
            pattern in filename.lower()
            for pattern in [".config", ".yml", ".yaml", ".json"]
        )

    def _analyze_git_history(self, workspace_path: str, depth: int) -> Dict[str, Any]:
        """Analyze git history for platform signatures"""
        git_data: Dict[str, Any] = {
            "commit_messages": [],
            "authors": [],
            "commit_patterns": {},
            "recent_activity": [],
        }

        try:
            # Get commit messages
            result = subprocess.run(
                ["git", "log", f"--max-count={depth}", "--pretty=format:%s||%an||%ad"],
                cwd=workspace_path,
                capture_output=True,
                text=True,
            )

            if result.returncode == 0:
                for line in result.stdout.strip().split("\n"):
                    if "||" in line:
                        message, author, date = line.split("||", 2)
                        git_data["commit_messages"].append(message)
                        git_data["authors"].append(author)
                        git_data["recent_activity"].append(
                            {"message": message, "author": author, "date": date}
                        )

                        # Track platform patterns in commits
                        for platform in self.all_platforms:
                            for pattern in self.all_platforms[platform].get(
                                "commit_patterns", []
                            ):
                                if pattern.lower() in message.lower():
                                    if platform not in git_data["commit_patterns"]:
                                        git_data["commit_patterns"][platform] = []
                                    git_data["commit_patterns"][platform].append(
                                        message
                                    )

        except Exception as e:
            print(f"Error analyzing git history: {e}")

        return git_data

    def _calculate_enhanced_platform_score(
        self,
        platform: str,
        signatures: Dict[str, Any],
        inputs: EnhancedPlatformDetectorInputs,
        file_structure: Dict[str, Any],
        package_json: Optional[Dict[str, Any]],
        git_history: Dict[str, Any],
    ) -> Tuple[float, Dict[str, Any]]:
        """Enhanced scoring with multiple signal sources"""

        score = 0.0
        analysis: Dict[str, Any] = {
            "file_matches": [],
            "dependency_matches": [],
            "commit_matches": [],
            "git_author_matches": [],
            "content_matches": [],
            "pattern_matches": [],
            "confidence_factors": [],
        }

        # 1. Configuration file detection (high confidence)
        for file_pattern in signatures.get("files", []):
            matches = [
                f
                for f in file_structure.get("files", [])
                if self._file_pattern_match(file_pattern, f)
            ]
            if matches:
                score += 0.4
                analysis["file_matches"].extend(matches)
                analysis["confidence_factors"].append(f"Config files: {len(matches)}")

        # 2. Folder pattern detection
        for folder_pattern in signatures.get("folder_patterns", []):
            matches = [
                f for f in file_structure.get("folders", []) if folder_pattern in f
            ]
            if matches:
                score += 0.2
                analysis["file_matches"].extend([f"folder: {m}" for m in matches])

        # 3. Git commit analysis (medium-high confidence)
        commit_score = 0.0
        for pattern in signatures.get("commit_patterns", []):
            matching_commits = [
                msg
                for msg in git_history.get("commit_messages", [])
                if pattern.lower() in msg.lower()
            ]
            if matching_commits:
                commit_score += 0.15 * min(len(matching_commits), 3)  # Cap at 3 commits
                analysis["commit_matches"].extend(matching_commits[:3])

        score += min(commit_score, 0.45)  # Cap commit score contribution

        # 4. Git author analysis (for AI assistants)
        if "git_patterns" in signatures:
            for pattern in signatures["git_patterns"]:
                matching_authors = [
                    author
                    for author in git_history.get("authors", [])
                    if pattern.lower() in author.lower()
                ]
                if matching_authors:
                    score += 0.3
                    analysis["git_author_matches"].extend(matching_authors)
                    analysis["confidence_factors"].append(f"AI co-authorship detected")

        # 5. Package.json analysis (medium confidence)
        if package_json:
            # Dependencies
            all_deps: Dict[str, Any] = {
                **package_json.get("dependencies", {}),
                **package_json.get("devDependencies", {}),
            }

            dep_score = 0.0
            for dep_pattern in signatures.get("dependencies", []):
                matching_deps = [
                    dep
                    for dep in all_deps.keys()
                    if self._dependency_pattern_match(dep_pattern, dep)
                ]
                if matching_deps:
                    dep_score += 0.25
                    analysis["dependency_matches"].extend(matching_deps)

            score += min(dep_score, 0.5)  # Cap dependency score

            # Scripts
            scripts = package_json.get("scripts", {})
            for script_pattern in signatures.get("package_scripts", []):
                if any(script_pattern in script for script in scripts.values()):
                    score += 0.15
                    analysis["pattern_matches"].append(f"script: {script_pattern}")

        # 6. File content analysis (medium confidence)
        content_score = 0.0
        for file_path, content in file_structure.get("file_contents", {}).items():
            for pattern in signatures.get("content_patterns", []):
                if pattern.lower() in content.lower():
                    content_score += 0.1
                    analysis["content_matches"].append(f"{pattern} in {file_path}")

        score += min(content_score, 0.3)  # Cap content score

        # 7. Platform-specific advanced detection
        advanced_score = self._advanced_platform_detection(
            platform, file_structure, package_json, git_history
        )
        score += advanced_score
        if advanced_score > 0:
            analysis["confidence_factors"].append(
                f"Advanced detection: +{advanced_score:.2f}"
            )

        return min(score, 1.0), analysis

    def _file_pattern_match(self, pattern: str, filename: str) -> bool:
        """Enhanced file pattern matching"""
        if "*" in pattern:
            # Handle glob patterns
            import fnmatch

            return fnmatch.fnmatch(filename, pattern)
        else:
            # Exact match or contains
            return pattern in filename or filename.endswith(pattern)

    def _dependency_pattern_match(self, pattern: str, dependency: str) -> bool:
        """Enhanced dependency pattern matching"""
        if "*" in pattern:
            # Handle wildcard patterns like @radix-ui/react-*
            import fnmatch

            return fnmatch.fnmatch(dependency, pattern)
        else:
            return pattern == dependency or pattern in dependency

    def _advanced_platform_detection(
        self,
        platform: str,
        file_structure: Dict[str, Any],
        package_json: Optional[Dict[str, Any]],
        git_history: Dict[str, Any],
    ) -> float:
        """Platform-specific advanced detection logic"""

        advanced_detectors: Dict[
            str,
            Callable[[Dict[str, Any], Optional[Dict[str, Any]], Dict[str, Any]], float],
        ] = {
            "cursor": self._detect_cursor_advanced,
            "v0_dev": self._detect_v0_advanced,
            "copilot_workspace": self._detect_copilot_advanced,
            "supabase_ai": self._detect_supabase_advanced,
            "figma_to_code": self._detect_figma_advanced,
            "replit": self._detect_replit_advanced,
        }

        if platform in advanced_detectors:
            return advanced_detectors[platform](
                file_structure, package_json, git_history
            )

        return 0.0

    def _detect_cursor_advanced(
        self,
        file_structure: Dict[str, Any],
        package_json: Optional[Dict[str, Any]],
        git_history: Dict[str, Any],
    ) -> float:
        """Advanced Cursor detection"""
        score = 0.0

        # Check for .cursorrules file content
        for file_path, content in file_structure.get("file_contents", {}).items():
            if ".cursorrules" in file_path:
                if any(
                    keyword in content.lower()
                    for keyword in ["ai assistant", "cursor", "code generation"]
                ):
                    score += 0.2

        # Check for Cursor-style comments
        for file_path, content in file_structure.get("file_contents", {}).items():
            if file_path.endswith((".ts", ".tsx", ".js", ".jsx", ".py")):
                if (
                    "// Generated by Cursor" in content
                    or "# Generated by Cursor" in content
                ):
                    score += 0.15

        return score

    def _detect_v0_advanced(
        self,
        file_structure: Dict[str, Any],
        package_json: Optional[Dict[str, Any]],
        git_history: Dict[str, Any],
    ) -> float:
        """Advanced v0.dev detection"""
        score = 0.0

        # Check for shadcn/ui components (common with v0.dev)
        if package_json:
            deps = {
                **package_json.get("dependencies", {}),
                **package_json.get("devDependencies", {}),
            }
            shadcn_indicators = [
                "@radix-ui/",
                "class-variance-authority",
                "clsx",
                "tailwind-merge",
            ]

            shadcn_count = sum(
                1
                for dep in deps.keys()
                if any(indicator in dep for indicator in shadcn_indicators)
            )

            if shadcn_count >= 3:
                score += 0.15

        # Check for v0-style component structure
        ui_components = [
            f
            for f in file_structure.get("files", [])
            if "components/ui/" in f and f.endswith((".tsx", ".ts"))
        ]

        if len(ui_components) >= 3:
            score += 0.1

        return score

    def _detect_copilot_advanced(
        self,
        file_structure: Dict[str, Any],
        package_json: Optional[Dict[str, Any]],
        git_history: Dict[str, Any],
    ) -> float:
        """Advanced GitHub Copilot detection"""
        score = 0.0

        # Check for Copilot co-authorship in git history
        copilot_commits = len(
            [
                author
                for author in git_history.get("authors", [])
                if "copilot" in author.lower() or "github" in author.lower()
            ]
        )

        if copilot_commits > 0:
            score += min(0.2, copilot_commits * 0.05)

        return score

    def _detect_supabase_advanced(
        self,
        file_structure: Dict[str, Any],
        package_json: Optional[Dict[str, Any]],
        git_history: Dict[str, Any],
    ) -> float:
        """Advanced Supabase AI detection"""
        score = 0.0

        # Check for Supabase configuration files
        supabase_files = [
            f
            for f in file_structure.get("files", [])
            if "supabase" in f.lower() and f.endswith((".sql", ".ts", ".js"))
        ]

        if supabase_files:
            score += min(0.15, len(supabase_files) * 0.05)

        return score

    def _detect_figma_advanced(
        self,
        file_structure: Dict[str, Any],
        package_json: Optional[Dict[str, Any]],
        git_history: Dict[str, Any],
    ) -> float:
        """Advanced Figma to Code detection"""
        score = 0.0

        # Check for design tokens structure
        design_token_files = [
            f
            for f in file_structure.get("files", [])
            if any(token in f.lower() for token in ["token", "design-system", "theme"])
        ]

        if design_token_files:
            score += 0.1

        return score

    def _detect_replit_advanced(
        self,
        file_structure: Dict[str, Any],
        package_json: Optional[Dict[str, Any]],
        git_history: Dict[str, Any],
    ) -> float:
        """Advanced Replit detection"""
        score = 0.0

        # Check for Replit-specific environment variables in content
        for file_path, content in file_structure.get("file_contents", {}).items():
            if any(var in content for var in ["REPL_ID", "REPL_OWNER", "REPL_SLUG"]):
                score += 0.15
                break

        return score

    def _determine_platform_hierarchy(
        self, all_scores: Dict[str, float]
    ) -> Tuple[str, List[str]]:
        """Determine primary platform and secondary platforms"""

        if not all_scores:
            return "unknown", []

        # Sort platforms by score
        sorted_platforms = sorted(all_scores.items(), key=lambda x: x[1], reverse=True)

        primary_platform = sorted_platforms[0][0]
        primary_score = sorted_platforms[0][1]

        # Determine secondary platforms (score > 0.3 and within 0.4 of primary)
        secondary_platforms = []
        for platform, score in sorted_platforms[1:]:
            if score > 0.3 and (primary_score - score) < 0.4:
                secondary_platforms.append(platform)

        # If primary score is too low, mark as unknown
        if primary_score < 0.3:
            primary_platform = "unknown"
            secondary_platforms = [p for p, s in sorted_platforms if s > 0.2]

        return primary_platform, secondary_platforms

    def _analyze_workflow_type(
        self,
        all_scores: Dict[str, float],
        primary_platform: str,
        secondary_platforms: List[str],
    ) -> Tuple[str, Optional[Dict[str, Any]]]:
        """Analyze the type of development workflow"""

        if primary_platform == "unknown":
            return "undetected", None

        if not secondary_platforms:
            return "single_platform", None

        # Check for known hybrid patterns
        platforms_involved = {primary_platform} | set(secondary_platforms)

        for pattern, workflow_name in self.hybrid_patterns.items():
            if set(pattern).issubset(platforms_involved):
                return "hybrid_workflow", {
                    "workflow_name": workflow_name,
                    "pattern": pattern,
                    "description": self._get_workflow_description(workflow_name),
                    "platforms_involved": list(platforms_involved),
                    "primary_platform": primary_platform,
                    "secondary_platforms": secondary_platforms,
                }

        # Generic multi-platform workflow
        return "multi_platform", {
            "platforms_involved": list(platforms_involved),
            "primary_platform": primary_platform,
            "secondary_platforms": secondary_platforms,
            "categories": self._categorize_platforms(platforms_involved),
        }

    def _get_workflow_description(self, workflow_name: str) -> str:
        """Get description for known workflow patterns"""
        descriptions: Dict[str, str] = {
            "ai_ide_to_web_design": "AI IDE development with web-first component design",
            "prototype_to_production_ide": "Rapid prototyping transitioning to production IDE",
            "design_system_workflow": "Design system to component library workflow",
            "backend_frontend_integration": "Backend-as-a-Service with frontend framework",
            "vercel_to_ide_workflow": "Vercel ecosystem with advanced IDE features",
            "ai_chat_to_ide": "AI chat interface to production IDE workflow",
            "open_source_ai_workflow": "Open-source AI tools workflow",
            "infrastructure_to_application": "Infrastructure-as-Code to application development",
        }

        return descriptions.get(workflow_name, "Multi-platform development workflow")

    def _categorize_platforms(self, platforms: set) -> Dict[str, List[str]]:
        """Categorize platforms by type"""
        categorized: Dict[str, List[str]] = {}

        for category, platform_list in self.platform_categories.items():
            category_platforms = [p for p in platforms if p in platform_list]
            if category_platforms:
                categorized[category] = category_platforms

        return categorized

    def _generate_platform_configs(
        self,
        primary_platform: str,
        secondary_platforms: List[str],
        file_structure: Dict[str, Any],
        package_json: Optional[Dict[str, Any]],
    ) -> Dict[str, Any]:
        """Generate platform-specific configurations"""

        configs: Dict[str, Any] = {}

        all_platforms = [primary_platform] + secondary_platforms

        for platform in all_platforms:
            if platform == "unknown":
                continue

            config: Dict[str, Any] = {
                "platform": platform,
                "detected_files": [],
                "recommended_enhancements": [],
                "deployment_options": [],
            }

            # Platform-specific configuration generation
            if platform in self.core_platforms:
                config.update(
                    self._generate_core_platform_config(
                        platform, file_structure, package_json
                    )
                )
            elif platform in self.ai_code_platforms:
                config.update(
                    self._generate_ai_platform_config(
                        platform, file_structure, package_json
                    )
                )
            elif platform in self.web_ai_platforms:
                config.update(
                    self._generate_web_platform_config(
                        platform, file_structure, package_json
                    )
                )

            configs[platform] = config

        return configs

    def _generate_core_platform_config(
        self,
        platform: str,
        file_structure: Dict[str, Any],
        package_json: Optional[Dict[str, Any]],
    ) -> Dict[str, Any]:
        """Generate configuration for core rapid prototyping platforms"""

        base_config: Dict[str, Any] = {
            "category": "rapid_prototyping",
            "production_ready": False,
            "enhancement_priority": "high",
        }

        if platform == "replit":
            base_config.update(
                {
                    "runtime_detected": self._detect_runtime(file_structure),
                    "deployment_options": ["azure-app-service", "vercel", "railway"],
                    "recommended_enhancements": [
                        "Add production package.json scripts",
                        "Implement environment variable management",
                        "Add Dockerfile for containerization",
                        "Setup CI/CD pipeline",
                    ],
                }
            )

        elif platform == "lovable":
            base_config.update(
                {
                    "framework": "react",
                    "typescript_detected": bool(
                        self._detect_typescript(file_structure)
                    ),
                    "deployment_options": [
                        "vercel",
                        "netlify",
                        "azure-static-web-apps",
                    ],
                    "recommended_enhancements": [
                        "Add comprehensive TypeScript configuration",
                        "Implement component testing",
                        "Setup Storybook documentation",
                        "Add accessibility testing",
                    ],
                }
            )

        return base_config

    def _generate_ai_platform_config(
        self,
        platform: str,
        file_structure: Dict[str, Any],
        package_json: Optional[Dict[str, Any]],
    ) -> Dict[str, Any]:
        """Generate configuration for AI code generation platforms"""

        return {
            "category": "ai_code_generation",
            "production_ready": True,
            "enhancement_priority": "medium",
            "ai_integration": True,
            "recommended_enhancements": [
                "Ensure AI-generated code follows best practices",
                "Add comprehensive testing for AI-generated components",
                "Implement code review for AI contributions",
                "Setup AI usage analytics",
            ],
        }

    def _generate_web_platform_config(
        self,
        platform: str,
        file_structure: Dict[str, Any],
        package_json: Optional[Dict[str, Any]],
    ) -> Dict[str, Any]:
        """Generate configuration for web-first AI platforms"""

        return {
            "category": "web_ai",
            "production_ready": True,
            "enhancement_priority": "low",
            "web_optimized": True,
            "recommended_enhancements": [
                "Optimize for production deployment",
                "Add performance monitoring",
                "Implement analytics tracking",
                "Setup error tracking",
            ],
        }

    def _generate_enhancement_recommendations(
        self,
        primary_platform: str,
        secondary_platforms: List[str],
        detailed_analysis: Dict[str, Dict[str, Any]],
    ) -> List[str]:
        """Generate platform-specific enhancement recommendations"""

        recommendations: List[str] = []

        # Primary platform recommendations
        if primary_platform != "unknown":
            recommendations.extend(self._get_platform_recommendations(primary_platform))

        # Secondary platform recommendations
        for platform in secondary_platforms:
            recommendations.extend(
                self._get_platform_recommendations(platform, secondary=True)
            )

        # Multi-platform recommendations
        if secondary_platforms:
            recommendations.extend(
                [
                    "Implement cross-platform configuration management",
                    "Add integration testing for multi-platform workflows",
                    "Document platform interaction patterns",
                ]
            )

        return list(set(recommendations))  # Remove duplicates

    def _get_platform_recommendations(
        self, platform: str, secondary: bool = False
    ) -> List[str]:
        """Get specific recommendations for a platform"""

        prefix = "Secondary: " if secondary else ""

        platform_recommendations: Dict[str, List[str]] = {
            "cursor": [
                f"{prefix}Optimize Cursor AI settings for team consistency",
                f"{prefix}Setup Cursor rules for project-specific guidelines",
            ],
            "v0_dev": [
                f"{prefix}Integrate v0 components with design system",
                f"{prefix}Add v0 component documentation",
            ],
            "replit": [
                f"{prefix}Enhance Replit project for production deployment",
                f"{prefix}Add production-ready dependencies and scripts",
            ],
            "supabase_ai": [
                f"{prefix}Implement Supabase edge functions",
                f"{prefix}Add database migration strategies",
            ],
        }

        return platform_recommendations.get(
            platform, [f"{prefix}Add platform-specific optimizations"]
        )

    def _generate_migration_opportunities(
        self, all_scores: Dict[str, float], primary_platform: str
    ) -> List[str]:
        """Generate migration opportunities to other platforms"""

        opportunities: List[str] = []

        # Sort platforms by score (excluding primary)
        other_platforms: Dict[str, float] = {
            k: v for k, v in all_scores.items() if k != primary_platform and v > 0.1
        }
        sorted_others = sorted(
            other_platforms.items(), key=lambda x: x[1], reverse=True
        )

        migration_benefits: Dict[str, str] = {
            "cursor": "Enhanced AI-driven development with advanced IDE features",
            "v0_dev": "Rapid UI component generation with Vercel ecosystem",
            "copilot_workspace": "Enterprise-grade AI assistance with GitHub integration",
            "continue": "Open-source AI development with customizable models",
            "supabase_ai": "Backend-as-a-Service with AI-powered features",
            "figma_to_code": "Design-to-code workflow for better design consistency",
        }

        for platform, score in sorted_others[:3]:  # Top 3 alternatives
            if score > 0.15:
                benefit = migration_benefits.get(
                    platform, "Platform-specific development benefits"
                )
                compatibility = f"{score:.1%}"
                opportunities.append(
                    f"Consider {platform}: {benefit} (compatibility: {compatibility})"
                )

        return opportunities

    def _detect_runtime(self, file_structure: Dict[str, Any]) -> str:
        """Detect primary runtime/language"""
        extensions = file_structure.get("file_extensions", {})

        if extensions.get(".py", 0) > extensions.get(".js", 0):
            return "python"
        elif extensions.get(".js", 0) > 0 or extensions.get(".ts", 0) > 0:
            return "nodejs"
        elif extensions.get(".java", 0) > 0:
            return "java"
        else:
            return "unknown"

    def _detect_typescript(self, file_structure: Dict[str, Any]) -> bool:
        """Detect TypeScript usage"""
        extensions = file_structure.get("file_extensions", {})
        return bool(extensions.get(".ts", 0) > 0 or extensions.get(".tsx", 0) > 0)

    def _parse_package_json(
        self, package_json_content: Optional[str], workspace_path: str
    ) -> Optional[Dict[str, Any]]:
        """
        Parse package.json content or load it from the workspace if not provided.
        Returns the parsed dict or None if not available/invalid.
        """
        import json
        import os
        from typing import cast

        if package_json_content:
            try:
                return cast(Optional[Dict[str, Any]], json.loads(package_json_content))
            except Exception:
                return None

        # Try to load from file if not provided
        package_json_path = os.path.join(workspace_path, "package.json")
        if os.path.exists(package_json_path):
            try:
                with open(package_json_path, "r", encoding="utf-8") as f:
                    return cast(Optional[Dict[str, Any]], json.load(f))
            except Exception:
                return None
        return None


# Entry point for AutoPR
def run(inputs_dict: dict) -> dict:
    """AutoPR entry point"""
    inputs = EnhancedPlatformDetectorInputs(**inputs_dict)
    detector = EnhancedPlatformDetector()
    outputs = detector.detect_platforms(inputs)
    return outputs.dict()


if __name__ == "__main__":
    # Test the enhanced detector
    sample_inputs = {
        "repository_url": "https://github.com/user/ai-project",
        "commit_messages": [
            "Initial commit from Cursor",
            "Added v0 components",
            "Deployed with Vercel",
        ],
        "workspace_path": ".",
        "git_log_depth": 50,
    }

    result = run(sample_inputs)
    print(json.dumps(result, indent=2))
